{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36224f33",
   "metadata": {},
   "source": [
    "#Clean Chroma Ingestion Pipeline: Cell-by-Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbff9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from pathlib import Path\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Always load your .env so API keys are set\n",
    "load_dotenv()\n",
    "DATA_PATH = \"data/books\"\n",
    "CHROMA_PATH = \"chroma_fresh\"  # Use a FRESH directory for every re-ingest during dev!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa10d32d",
   "metadata": {},
   "source": [
    "#Cell 2: Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faf0847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents.\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    docs = []\n",
    "    for path in Path(DATA_PATH).glob(\"*.md\"):\n",
    "        loader = TextLoader(str(path), encoding=\"utf-8\")\n",
    "        docs.extend(loader.load())\n",
    "    print(f\"Loaded {len(docs)} documents.\")\n",
    "    return docs\n",
    "\n",
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f553f",
   "metadata": {},
   "source": [
    "#Cell 3: Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77922d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 217 chunks.\n"
     ]
    }
   ],
   "source": [
    "def split_text(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    return chunks\n",
    "\n",
    "chunks = split_text(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bab3f7",
   "metadata": {},
   "source": [
    "#Chunk Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ccaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 0 ---\n",
      "The Project Gutenberg eBook of Alice's Adventures in Wonderland\n",
      "\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenb\n",
      "{'source': 'data\\\\books\\\\alice_in_wonderland.md', 'start_index': 0}\n",
      "--- Chunk 1 ---\n",
      "**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\n",
      "[Illustration]\n",
      "\n",
      "Aliceâ€™s Adventures in Wonderland\n",
      "\n",
      "by Lewis Carroll\n",
      "\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "Contents\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "CHAPTER II. The Pool of Tears\n",
      "CHAPTER III. A Caucus-Race and a Long Tale\n",
      "CHA\n",
      "{'source': 'data\\\\books\\\\alice_in_wonderland.md', 'start_index': 714}\n",
      "--- Chunk 2 ---\n",
      "So she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure of\n",
      "making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
      "close by her.\n",
      "{'source': 'data\\\\books\\\\alice_in_wonderland.md', 'start_index': 1661}\n"
     ]
    }
   ],
   "source": [
    "#for i, chunk in enumerate(chunks[:3]):\n",
    "    #print(f\"--- Chunk {i} ---\")\n",
    "    #print(chunk.page_content[:300])  # show first 300 characters\n",
    "    #print(chunk.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe44f3a2",
   "metadata": {},
   "source": [
    "#Cell 4: (Optional) Sanity Check for Target Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = False\n",
    "for i, doc in enumerate(chunks):\n",
    "    if \"after such a fall as this\" in doc.page_content:\n",
    "        print(f\"\\nChunk {i}:\")\n",
    "        print(doc.page_content)\n",
    "        print(doc.metadata)\n",
    "        found = True\n",
    "if not found:\n",
    "    print(\"Phrase not found in any chunk. Check chunk_size or source document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b07425",
   "metadata": {},
   "source": [
    "#Cell 5: Garbage Collection & Ensure No Chroma Locks Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6999b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del db\n",
    "except NameError:\n",
    "    pass  # No db object present\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86753873",
   "metadata": {},
   "source": [
    "#Cell 6: Delete Old DB Folder (if it exists) and Save Chunks to Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e57687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 217 chunks to chroma_fresh.\n"
     ]
    }
   ],
   "source": [
    "# Delete previous vector store to avoid file-lock issues and ensure a clean ingest\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "# Build new embeddings object\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Create and persist the Chroma vector DB\n",
    "db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    persist_directory=CHROMA_PATH\n",
    ")\n",
    "print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff4b62",
   "metadata": {},
   "source": [
    "#Cell 7: Confirm DB Content (Debugging/Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f794e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks in vector DB: 217\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks in vector DB:\", db._collection.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
